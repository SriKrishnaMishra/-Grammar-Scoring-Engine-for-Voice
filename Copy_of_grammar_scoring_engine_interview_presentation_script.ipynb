{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhqgLVBzq/Voufm3oiZOUA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SriKrishnaMishra/-Grammar-Scoring-Engine-for-Voice/blob/main/Copy_of_grammar_scoring_engine_interview_presentation_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment Setup & Data Exploration"
      ],
      "metadata": {
        "id": "Nl0WGxe-Eszn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "vs0wH3MZEf9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List all files in the dataset"
      ],
      "metadata": {
        "id": "1eDFhUQLEv1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìÇ Dataset Structure:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define the base directory where audio and CSV files might be found\n",
        "# In Colab, you typically upload files to /content/\n",
        "base_dataset_path = '/content/audio_data' # Suggest a new path for user to upload files\n",
        "\n",
        "audio_files = []\n",
        "csv_files = []\n",
        "\n",
        "# Check if the directory exists before walking through it\n",
        "if os.path.exists(base_dataset_path):\n",
        "    for dirname, _, filenames in os.walk(base_dataset_path):\n",
        "        for filename in filenames:\n",
        "            filepath = os.path.join(dirname, filename)\n",
        "            print(filepath)\n",
        "\n",
        "            if filename.endswith(('.wav', '.mp3', '.m4a', '.flac')):\n",
        "                audio_files.append(filepath)\n",
        "            elif filename.endswith('.csv'):\n",
        "                csv_files.append(filepath)\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Base dataset path '{base_dataset_path}' does not exist. Please upload your files or specify the correct path.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"‚úÖ Found {len(audio_files)} audio files\")\n",
        "print(f\"‚úÖ Found {len(csv_files)} CSV files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bw3HKBTEl3F",
        "outputId": "74de5e5a-918e-4fa4-f223-9eebe755f4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Dataset Structure:\n",
            "============================================================\n",
            "‚ö†Ô∏è Base dataset path '/content/audio_data' does not exist. Please upload your files or specify the correct path.\n",
            "\n",
            "============================================================\n",
            "‚úÖ Found 0 audio files\n",
            "‚úÖ Found 0 CSV files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CSV data if available"
      ],
      "metadata": {
        "id": "Xyad2S2lEyED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if csv_files:\n",
        "    print(f\"\\nüìä Loading CSV: {csv_files[0]}\")\n",
        "    df_labels = pd.read_csv(csv_files[0])\n",
        "    print(f\"Shape: {df_labels.shape}\")\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(df_labels.head())\n",
        "    print(\"\\nColumns:\", df_labels.columns.tolist())\n",
        "    print(\"\\nData types:\")\n",
        "    print(df_labels.dtypes)"
      ],
      "metadata": {
        "id": "WH9zrL80Epe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Packages\n"
      ],
      "metadata": {
        "id": "wvzcRE1EE0Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîß Installing required packages...\")\n",
        "print(\"This will take 5-7 minutes. Please wait...\")\n",
        "\n",
        "# Install packages\n",
        "import sys\n",
        "!{sys.executable} -m pip install -q openai-whisper\n",
        "!{sys.executable} -m pip install -q language-tool-python\n",
        "!{sys.executable} -m pip install -q textstat\n",
        "!{sys.executable} -m pip install -q transformers\n",
        "!{sys.executable} -m pip install -q soundfile\n",
        "!{sys.executable} -m pip install -q librosa\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBmMPEXSFeGr",
        "outputId": "1552389a-7229-4065-d598-4fdc06c2c244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß Installing required packages...\n",
            "This will take 5-7 minutes. Please wait...\n",
            "‚úÖ All packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "ShjDceAfFiIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import whisper\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "import language_tool_python\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import textstat"
      ],
      "metadata": {
        "id": "XJ0O7sx3FkKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML libraries"
      ],
      "metadata": {
        "id": "l-RtZCgzGFxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression"
      ],
      "metadata": {
        "id": "OSvIZ_iIGIAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization"
      ],
      "metadata": {
        "id": "owzDs745GL1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "print(\"‚úÖ All libraries imported!\")\n",
        "print(f\"üñ•Ô∏è GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"üñ•Ô∏è Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkx7W922GQQ6",
        "outputId": "1f99a13a-7516-4870-95d2-9cb6207efba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries imported!\n",
            "üñ•Ô∏è GPU Available: False\n",
            "üñ•Ô∏è Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speech-to-Text Module"
      ],
      "metadata": {
        "id": "ZeVK_kDFGXIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeechTranscriber:\n",
        "    \"\"\"Converts audio files to text using Whisper\"\"\"\n",
        "\n",
        "    def __init__(self, model_size='base'):\n",
        "        print(f\"üé§ Loading Whisper '{model_size}' model...\")\n",
        "        self.model = whisper.load_model(model_size)\n",
        "        print(\"‚úÖ Whisper model loaded!\")\n",
        "\n",
        "    def transcribe(self, audio_path):\n",
        "        \"\"\"Transcribe audio file to text\"\"\"\n",
        "        try:\n",
        "            # Load audio with Whisper\n",
        "            result = self.model.transcribe(audio_path, language='en', fp16=False)\n",
        "            return result['text'].strip()\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error transcribing {audio_path}: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def transcribe_batch(self, audio_paths, show_progress=True):\n",
        "        \"\"\"Transcribe multiple audio files\"\"\"\n",
        "        transcripts = []\n",
        "\n",
        "        for i, audio_path in enumerate(audio_paths, 1):\n",
        "            if show_progress and i % 10 == 0:\n",
        "                print(f\"Progress: {i}/{len(audio_paths)}\")\n",
        "\n",
        "            transcript = self.transcribe(audio_path)\n",
        "            transcripts.append(transcript)\n",
        "\n",
        "        return transcripts\n",
        "        # Initialize transcriber\n",
        "transcriber = SpeechTranscriber(model_size='base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z19PPgCGf_c",
        "outputId": "e4617d29-b4f0-4c17-eb57-9f61e4b57ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé§ Loading Whisper 'base' model...\n",
            "‚úÖ Whisper model loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grammar Feature Extraction Module"
      ],
      "metadata": {
        "id": "jnOJkQlJGkpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GrammarFeatureExtractor:\n",
        "    \"\"\"Extracts grammar-related features from text\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"üìù Initializing grammar tools...\")\n",
        "\n",
        "        # Grammar checker\n",
        "        print(\"  Loading LanguageTool...\")\n",
        "        self.grammar_tool = language_tool_python.LanguageTool('en-US')\n",
        "\n",
        "        # Grammar correction model\n",
        "        print(\"  Loading T5 Grammar Correction model...\")\n",
        "        try:\n",
        "            self.gec_tokenizer = AutoTokenizer.from_pretrained(\"vennify/t5-base-grammar-correction\")\n",
        "            self.gec_model = AutoModelForSeq2SeqLM.from_pretrained(\"vennify/t5-base-grammar-correction\")\n",
        "            self.gec_available = True\n",
        "        except:\n",
        "            print(\"  ‚ö†Ô∏è T5 model not available, will use basic features only\")\n",
        "            self.gec_available = False\n",
        "\n",
        "        print(\"‚úÖ Grammar tools ready!\")\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Remove fillers and clean text\"\"\"\n",
        "        if not text or len(text.strip()) == 0:\n",
        "            return \"\"\n",
        "\n",
        "        # Common fillers in speech\n",
        "        fillers = [\n",
        "            ' uh ', ' um ', ' hmm ', ' ah ',\n",
        "            ' you know ', ' i mean ', ' like ',\n",
        "            ' basically ', ' actually ', ' literally ',\n",
        "            ' so yeah ', ' right ', ' okay '\n",
        "        ]\n",
        "\n",
        "        text_lower = ' ' + text.lower() + ' '\n",
        "        for filler in fillers:\n",
        "            text_lower = text_lower.replace(filler, ' ')\n",
        "\n",
        "        # Clean up extra spaces\n",
        "        text_lower = ' '.join(text_lower.split())\n",
        "        return text_lower.strip()\n",
        "\n",
        "    def count_grammar_errors(self, text):\n",
        "        \"\"\"Count grammar errors using LanguageTool\"\"\"\n",
        "        if not text or len(text.strip()) == 0:\n",
        "            return 0\n",
        "\n",
        "        try:\n",
        "            matches = self.grammar_tool.check(text)\n",
        "            return len(matches)\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def get_correction_edits(self, text):\n",
        "        \"\"\"Get number of corrections needed\"\"\"\n",
        "        if not text or len(text.strip()) == 0 or not self.gec_available:\n",
        "            return 0\n",
        "\n",
        "        try:\n",
        "            # Prepare input\n",
        "            input_text = \"grammar: \" + text[:512]  # Limit length\n",
        "            input_ids = self.gec_tokenizer.encode(\n",
        "                input_text,\n",
        "                return_tensors='pt',\n",
        "                max_length=512,\n",
        "                truncation=True\n",
        "            )\n",
        "\n",
        "            # Generate correction\n",
        "            with torch.no_grad():\n",
        "                outputs = self.gec_model.generate(\n",
        "                    input_ids,\n",
        "                    max_length=512,\n",
        "                    num_beams=4,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            corrected = self.gec_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Calculate edit distance (simple word-level)\n",
        "            original_words = text.split()\n",
        "            corrected_words = corrected.split()\n",
        "\n",
        "            edit_count = abs(len(original_words) - len(corrected_words))\n",
        "            edit_count += sum(o != c for o, c in zip(original_words, corrected_words))\n",
        "\n",
        "            return edit_count\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def extract_features(self, text):\n",
        "        \"\"\"Extract all grammar features from text\"\"\"\n",
        "        if not text or len(text.strip()) == 0:\n",
        "            return self._empty_features()\n",
        "\n",
        "        # Clean text\n",
        "        cleaned_text = self.clean_text(text)\n",
        "\n",
        "        # Basic statistics\n",
        "        words = cleaned_text.split()\n",
        "        word_count = len(words)\n",
        "        char_count = len(cleaned_text)\n",
        "\n",
        "        if word_count == 0:\n",
        "            return self._empty_features()\n",
        "\n",
        "        # Sentence count\n",
        "        sentence_endings = cleaned_text.count('.') + cleaned_text.count('!') + cleaned_text.count('?')\n",
        "        sentence_count = max(1, sentence_endings)\n",
        "\n",
        "        # Grammar errors\n",
        "        error_count = self.count_grammar_errors(cleaned_text)\n",
        "\n",
        "        # Correction edits\n",
        "        edit_count = self.get_correction_edits(cleaned_text)\n",
        "\n",
        "        # Readability metrics\n",
        "        try:\n",
        "            flesch_reading = textstat.flesch_reading_ease(cleaned_text)\n",
        "            flesch_kincaid = textstat.flesch_kincaid_grade(cleaned_text)\n",
        "        except:\n",
        "            flesch_reading = 50.0\n",
        "            flesch_kincaid = 8.0\n",
        "\n",
        "        # Advanced features\n",
        "        avg_word_length = char_count / word_count\n",
        "        avg_sentence_length = word_count / sentence_count\n",
        "\n",
        "        # Punctuation features\n",
        "        comma_count = cleaned_text.count(',')\n",
        "        semicolon_count = cleaned_text.count(';')\n",
        "\n",
        "        # Vocabulary complexity (unique words ratio)\n",
        "        unique_words = len(set(words))\n",
        "        vocab_diversity = unique_words / word_count if word_count > 0 else 0\n",
        "\n",
        "        features = {\n",
        "            'word_count': word_count,\n",
        "            'char_count': char_count,\n",
        "            'sentence_count': sentence_count,\n",
        "            'error_count': error_count,\n",
        "            'edit_count': edit_count,\n",
        "            'errors_per_word': error_count / word_count,\n",
        "            'edits_per_word': edit_count / word_count,\n",
        "            'flesch_reading_ease': flesch_reading,\n",
        "            'flesch_kincaid_grade': flesch_kincaid,\n",
        "            'avg_word_length': avg_word_length,\n",
        "            'avg_sentence_length': avg_sentence_length,\n",
        "            'comma_count': comma_count,\n",
        "            'semicolon_count': semicolon_count,\n",
        "            'vocab_diversity': vocab_diversity,\n",
        "            'punctuation_per_sentence': (comma_count + semicolon_count) / sentence_count\n",
        "        }\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _empty_features(self):\n",
        "        \"\"\"Return empty feature dict\"\"\"\n",
        "        return {\n",
        "            'word_count': 0, 'char_count': 0, 'sentence_count': 0,\n",
        "            'error_count': 0, 'edit_count': 0, 'errors_per_word': 0,\n",
        "            'edits_per_word': 0, 'flesch_reading_ease': 0,\n",
        "            'flesch_kincaid_grade': 0, 'avg_word_length': 0,\n",
        "            'avg_sentence_length': 0, 'comma_count': 0,\n",
        "            'semicolon_count': 0, 'vocab_diversity': 0,\n",
        "            'punctuation_per_sentence': 0\n",
        "        }\n",
        "\n",
        "# Initialize feature extractor\n",
        "feature_extractor = GrammarFeatureExtractor()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzqxYbbnG661",
        "outputId": "8496c4d2-04b6-4c40-e252-bbe8424ddcfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Initializing grammar tools...\n",
            "  Loading LanguageTool...\n",
            "  Loading T5 Grammar Correction model...\n",
            "‚úÖ Grammar tools ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process All Audio Files"
      ],
      "metadata": {
        "id": "5tSyAODlG_6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üéµ Processing audio files...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create results list\n",
        "results = []\n",
        "\n",
        "# Process each audio file\n",
        "for i, audio_path in enumerate(audio_files, 1):\n",
        "    filename = os.path.basename(audio_path)\n",
        "    print(f\"\\n[{i}/{len(audio_files)}] Processing: {filename}\")\n",
        "\n",
        "    try:\n",
        "        # Transcribe audio\n",
        "        print(\"  üé§ Transcribing...\")\n",
        "        transcript = transcriber.transcribe(audio_path)\n",
        "\n",
        "        if not transcript:\n",
        "            print(\"  ‚ö†Ô∏è Empty transcript, skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"  üìù Transcript: {transcript[:100]}...\")\n",
        "\n",
        "        # Extract features\n",
        "        print(\"  üîç Extracting features...\")\n",
        "        features = feature_extractor.extract_features(transcript)\n",
        "\n",
        "        # Combine results\n",
        "        result = {\n",
        "            'filename': filename,\n",
        "            'audio_path': audio_path,\n",
        "            'transcript': transcript,\n",
        "            **features\n",
        "        }\n",
        "\n",
        "        results.append(result)\n",
        "        print(f\"  ‚úÖ Done! Errors: {features['error_count']}, Edits: {features['edit_count']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Error: {e}\")\n",
        "        continue\n",
        "\n",
        "# Create DataFrame\n",
        "df_processed = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"‚úÖ Successfully processed {len(df_processed)} audio files!\")\n",
        "\n",
        "# Display results\n",
        "print(\"\\nüìä Processed Data Preview:\")\n",
        "print(df_processed.head())\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "output_dir = '/kaggle/working'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save intermediate results\n",
        "df_processed.to_csv(os.path.join(output_dir, 'processed_transcripts.csv'), index=False)\n",
        "print(f\"\\nüíæ Saved transcripts to: {os.path.join(output_dir, 'processed_transcripts.csv')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujAFJHasHP4s",
        "outputId": "1bfdf0d2-02b4-4679-f978-489e6f8c91f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéµ Processing audio files...\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "‚úÖ Successfully processed 0 audio files!\n",
            "\n",
            "üìä Processed Data Preview:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "\n",
            "üíæ Saved transcripts to: /kaggle/working/processed_transcripts.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Merge with Labels and Prepare Training Data"
      ],
      "metadata": {
        "id": "d0LOue61HV-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîó Merging with labels...\")\n",
        "\n",
        "# Try different column names for matching\n",
        "possible_filename_cols = ['filename', 'file', 'audio_file', 'file_name', 'id']\n",
        "possible_score_cols = ['score', 'grammar_score', 'label', 'rating', 'target']\n",
        "\n",
        "# Find correct column names\n",
        "filename_col = None\n",
        "score_col = None\n",
        "\n",
        "if csv_files and len(df_labels) > 0:\n",
        "    for col in possible_filename_cols:\n",
        "        if col in df_labels.columns:\n",
        "            filename_col = col\n",
        "            break\n",
        "\n",
        "    for col in possible_score_cols:\n",
        "        if col in df_labels.columns:\n",
        "            score_col = col\n",
        "            break\n",
        "\n",
        "    if filename_col and score_col:\n",
        "        print(f\"  Using filename column: '{filename_col}'\")\n",
        "        print(f\"  Using score column: '{score_col}'\")\n",
        "\n",
        "        # Merge datasets\n",
        "        df_full = df_processed.merge(\n",
        "            df_labels[[filename_col, score_col]],\n",
        "            left_on='filename',\n",
        "            right_on=filename_col,\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Rename score column\n",
        "        df_full = df_full.rename(columns={score_col: 'grammar_score'})\n",
        "\n",
        "        print(f\"\\n‚úÖ Merged successfully!\")\n",
        "        print(f\"  Total samples: {len(df_full)}\")\n",
        "        print(f\"  Samples with labels: {df_full['grammar_score'].notna().sum()}\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Could not find matching columns. Using processed data only.\")\n",
        "        df_full = df_processed.copy()\n",
        "        df_full['grammar_score'] = np.nan\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No labels available. Will use unsupervised approach.\")\n",
        "    df_full = df_processed.copy()\n",
        "    df_full['grammar_score'] = np.nan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5MchE9VHiUK",
        "outputId": "522814a5-e951-4dc4-bde6-79408e5ddd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîó Merging with labels...\n",
            "‚ö†Ô∏è No labels available. Will use unsupervised approach.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Display statistics"
      ],
      "metadata": {
        "id": "ctWr31a4HmMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìà Score Distribution:\")\n",
        "if df_full['grammar_score'].notna().any():\n",
        "    print(df_full['grammar_score'].describe())\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    df_full['grammar_score'].hist(bins=20, edgecolor='black')\n",
        "    plt.xlabel('Grammar Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Score Distribution')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    df_full.boxplot(column='grammar_score')\n",
        "    plt.ylabel('Grammar Score')\n",
        "    plt.title('Score Box Plot')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/kaggle/working/score_distribution.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No labels available for visualization.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JSeuaSfHr-d",
        "outputId": "b9777d81-8776-401e-904b-220d1f5fa1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìà Score Distribution:\n",
            "No labels available for visualization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Analysis and Selection (FIXED)"
      ],
      "metadata": {
        "id": "ehH6qeytLmt_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74385092",
        "outputId": "a05683ed-224f-4200-a9e5-22aefbc7cbcd"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the target directory for audio files\n",
        "base_dataset_path = '/content/audio_data'\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "if not os.path.exists(base_dataset_path):\n",
        "    os.makedirs(base_dataset_path)\n",
        "    print(f\"Created directory: {base_dataset_path}\")\n",
        "else:\n",
        "    print(f\"Directory already exists: {base_dataset_path}\")\n",
        "\n",
        "print(\"Please upload your audio files (.wav, .mp3, etc.) into this directory now.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: /content/audio_data\n",
            "Please upload your audio files (.wav, .mp3, etc.) into this directory now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "XnPDYNVeMzt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nü§ñ Training machine learning models...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if we have labels\n",
        "if df_full['grammar_score'].notna().sum() < 10:\n",
        "    print(\"‚ö†Ô∏è Not enough labeled samples for training.\")\n",
        "    print(\"Creating heuristic scoring model instead...\")\n",
        "\n",
        "    # Heuristic scoring function\n",
        "    def heuristic_score(row):\n",
        "        \"\"\"Simple heuristic based on error rates\"\"\"\n",
        "        base_score = 5.0\n",
        "\n",
        "        # Penalize errors\n",
        "        error_penalty = row['errors_per_word'] * 10\n",
        "        edit_penalty = row['edits_per_word'] * 5\n",
        "\n",
        "        # Bonus for good readability\n",
        "        readability_bonus = 0\n",
        "        if 60 <= row['flesch_reading_ease'] <= 80:\n",
        "            readability_bonus = 0.3\n",
        "\n",
        "        # Calculate final score\n",
        "        score = base_score - error_penalty - edit_penalty + readability_bonus\n",
        "        return max(0, min(5, score))\n",
        "\n",
        "    df_full['predicted_score'] = df_full.apply(heuristic_score, axis=1)\n",
        "    print(\"‚úÖ Heuristic scoring applied!\")\n",
        "\n",
        "else:\n",
        "    # We have labels - train ML models\n",
        "    print(f\"‚úÖ Found {df_full['grammar_score'].notna().sum()} labeled samples\")\n",
        "\n",
        "    # Prepare data\n",
        "    df_train = df_full[df_full['grammar_score'].notna()].copy()\n",
        "    X = df_train[available_features].fillna(0)\n",
        "    y = df_train['grammar_score']\n",
        "\n",
        "    # Handle any infinite values\n",
        "    X = X.replace([np.inf, -np.inf], 0)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=pd.qcut(y, q=3, duplicates='drop')\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining set: {len(X_train)} samples\")\n",
        "    print(f\"Test set: {len(X_test)} samples\")\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Train multiple models\n",
        "    models = {\n",
        "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=5),\n",
        "        'Ridge Regression': Ridge(alpha=1.0),\n",
        "        'Lasso Regression': Lasso(alpha=0.1)\n",
        "    }\n",
        "\n",
        "    results_dict = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nüîß Training {name}...\")\n",
        "\n",
        "        # Train\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Evaluate\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        results_dict[name] = {\n",
        "            'model': model,\n",
        "            'mae': mae,\n",
        "            'rmse': rmse,\n",
        "            'r2': r2,\n",
        "            'predictions': y_pred\n",
        "        }\n",
        "\n",
        "        print(f\"  MAE:  {mae:.3f}\")\n",
        "        print(f\"  RMSE: {rmse:.3f}\")\n",
        "        print(f\"  R¬≤:   {r2:.3f}\")\n",
        "\n",
        "    # Select best model\n",
        "    best_model_name = min(results_dict.keys(), key=lambda k: results_dict[k]['mae'])\n",
        "    best_model = results_dict[best_model_name]['model']\n",
        "\n",
        "    print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
        "    print(f\"   MAE: {results_dict[best_model_name]['mae']:.3f}\")\n",
        "\n",
        "    # Predict on all data\n",
        "    X_all = df_full[available_features].fillna(0).replace([np.inf, -np.inf], 0)\n",
        "    X_all_scaled = scaler.transform(X_all)\n",
        "    df_full['predicted_score'] = best_model.predict(X_all_scaled)\n",
        "\n",
        "    # Clip predictions to valid range\n",
        "    df_full['predicted_score'] = df_full['predicted_score'].clip(0, 5)\n",
        "\n",
        "    # Visualize results\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(y_test, results_dict[best_model_name]['predictions'], alpha=0.6)\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "    plt.xlabel('Actual Score')\n",
        "    plt.ylabel('Predicted Score')\n",
        "    plt.title(f'{best_model_name} - Predictions vs Actual')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    model_names = list(results_dict.keys())\n",
        "    maes = [results_dict[m]['mae'] for m in model_names]\n",
        "    plt.barh(model_names, maes)\n",
        "    plt.xlabel('Mean Absolute Error')\n",
        "    plt.title('Model Comparison')\n",
        "    plt.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/kaggle/working/model_performance.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Feature importance (for tree-based models)\n",
        "    if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': available_features,\n",
        "            'importance': best_model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        print(\"\\nüìä Top 10 Most Important Features:\")\n",
        "        print(feature_importance.head(10))\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
        "        plt.title('Top 10 Feature Importances')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('/kaggle/working/feature_importance.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj7yGfBlM5Zz",
        "outputId": "2b4e5764-e26e-4f9f-ce0d-8003c8de9f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ Training machine learning models...\n",
            "============================================================\n",
            "‚ö†Ô∏è Not enough labeled samples for training.\n",
            "Creating heuristic scoring model instead...\n",
            "‚úÖ Heuristic scoring applied!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Submission File"
      ],
      "metadata": {
        "id": "Fcae66-8NfP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n‚ÜóÔ∏è Creating submission file...\")\n",
        "\n",
        "# Check if df_full is empty or has no processed data\n",
        "if df_full.empty or 'predicted_score' not in df_full.columns:\n",
        "    print(\"\\n‚ö†Ô∏è No processed audio files found or predicted scores available.\")\n",
        "    print(\"Please ensure you have uploaded your audio files to '/content/audio_data' \")\n",
        "    print(\"and re-run all cells from the 'Environment Setup & Data Exploration' section.\")\n",
        "else:\n",
        "    # Create submission DataFrame\n",
        "    submission = df_full[['filename', 'predicted_score']].copy()\n",
        "    submission = submission.rename(columns={'predicted_score': 'grammar_score'})\n",
        "\n",
        "    # Round scores to reasonable precision\n",
        "    submission['grammar_score'] = submission['grammar_score'].round(2)\n",
        "\n",
        "    # Display sample\n",
        "    print(\"\\nüìã Submission Preview:\")\n",
        "    print(submission.head(10))\n",
        "\n",
        "    print(f\"\\nüìä Submission Statistics:\")\n",
        "    print(submission['grammar_score'].describe())\n",
        "\n",
        "    # Save submission\n",
        "    submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
        "    print(\"\\n‚úÖ Submission saved to: /kaggle/working/submission.csv\")\n",
        "\n",
        "    # Also save detailed results\n",
        "    detailed_results = df_full[['filename', 'transcript', 'error_count', 'edit_count',\n",
        "                                 'errors_per_word', 'flesch_reading_ease', 'predicted_score']].copy()\n",
        "    detailed_results.to_csv('/kaggle/working/detailed_results.csv', index=False)\n",
        "    print(\"‚úÖ Detailed results saved to: /kaggle/working/detailed_results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzJJz5Z-Nibl",
        "outputId": "b0d2c5aa-1011-4234-ae6c-69e9598b3b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ÜóÔ∏è Creating submission file...\n",
            "\n",
            "‚ö†Ô∏è No processed audio files found or predicted scores available.\n",
            "Please ensure you have uploaded your audio files to '/content/audio_data' \n",
            "and re-run all cells from the 'Environment Setup & Data Exploration' section.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Visualizations and Analysis\n"
      ],
      "metadata": {
        "id": "733n1nS5OTSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "print(\"\\nüìä Creating final visualizations...\")\n",
        "\n",
        "# Check if df_full exists and is not empty\n",
        "if 'df_full' not in locals() or df_full.empty:\n",
        "    print(\"\\n‚ö†Ô∏è df_full DataFrame is not defined or is empty.\")\n",
        "    print(\"Please ensure audio files have been uploaded to '/content/audio_data' and all previous cells (especially 'Process All Audio Files' and 'Merge with Labels') have been successfully executed.\")\n",
        "else:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # 1. Score distribution\n",
        "    axes[0, 0].hist(df_full['predicted_score'], bins=30, edgecolor='black', alpha=0.7)\n",
        "    axes[0, 0].set_xlabel('Predicted Grammar Score')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].set_title('Distribution of Predicted Scores')\n",
        "    axes[0, 0].grid(True, alpha=0.3);\n",
        "\n",
        "    # 2. Error count vs Score\n",
        "    axes[0, 1].scatter(df_full['error_count'], df_full['predicted_score'], alpha=0.5)\n",
        "    axes[0, 1].set_xlabel('Grammar Error Count')\n",
        "    axes[0, 1].set_ylabel('Predicted Score')\n",
        "    axes[0, 1].set_title('Grammar Errors vs Score')\n",
        "    axes[0, 1].grid(True, alpha=0.3);\n",
        "\n",
        "    # 3. Readability vs Score\n",
        "    axes[1, 0].scatter(df_full['flesch_reading_ease'], df_full['predicted_score'], alpha=0.5, c='green')\n",
        "    axes[1, 0].set_xlabel('Flesch Reading Ease')\n",
        "    axes[1, 0].set_ylabel('Predicted Score')\n",
        "    axes[1, 0].set_title('Readability vs Score')\n",
        "    axes[1, 0].grid(True, alpha=0.3);\n",
        "\n",
        "    # 4. Word count vs Score\n",
        "    axes[1, 1].scatter(df_full['word_count'], df_full['predicted_score'], alpha=0.5, c='orange')\n",
        "    axes[1, 1].set_xlabel('Word Count')\n",
        "    axes[1, 1].set_ylabel('Predicted Score')\n",
        "    axes[1, 1].set_title('Word Count vs Score')\n",
        "    axes[1, 1].grid(True, alpha=0.3);\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/kaggle/working/final_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"‚úÖ Visualizations saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOr-JuelOY2M",
        "outputId": "fa0f1082-df50-475e-9cc6-a87287716270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Creating final visualizations...\n",
            "\n",
            "‚ö†Ô∏è df_full DataFrame is not defined or is empty.\n",
            "Please ensure audio files have been uploaded to '/content/audio_data' and all previous cells (especially 'Process All Audio Files' and 'Merge with Labels') have been successfully executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary Report"
      ],
      "metadata": {
        "id": "AOfa0sNzOetC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã GRAMMAR SCORING ENGINE - FINAL REPORT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if df_full exists and is not empty\n",
        "if 'df_full' in locals() and not df_full.empty:\n",
        "    print(f\"\\nüìä Dataset Summary:\")\n",
        "    print(f\"  Total audio files processed: {len(df_full)}\")\n",
        "    print(f\"  Average transcript length: {df_full['word_count'].mean():.1f} words\")\n",
        "    print(f\"  Average grammar errors: {df_full['error_count'].mean():.2f}\")\n",
        "    print(f\"  Average correction edits: {df_full['edit_count'].mean():.2f}\")\n",
        "\n",
        "    print(f\"\\n‚≠ê Score Summary:\")\n",
        "    print(f\"  Mean score: {df_full['predicted_score'].mean():.2f}\")\n",
        "    print(f\"  Median score: {df_full['predicted_score'].median():.2f}\")\n",
        "    print(f\"  Std deviation: {df_full['predicted_score'].std():.2f}\")\n",
        "    print(f\"  Min score: {df_full['predicted_score'].min():.2f}\")\n",
        "    print(f\"  Max score: {df_full['predicted_score'].max():.2f}\")\n",
        "\n",
        "    print(f\"\\nüìà Score Distribution:\")\n",
        "    score_ranges = pd.cut(df_full['predicted_score'], bins=[0, 1, 2, 3, 4, 5], labels=['0-1', '1-2', '2-3', '3-4', '4-5'])\n",
        "    print(score_ranges.value_counts().sort_index())\n",
        "\n",
        "    if df_full['grammar_score'].notna().any():\n",
        "        # Ensure results_dict and best_model_name are defined if labels were used\n",
        "        if 'results_dict' in locals() and 'best_model_name' in locals() and best_model_name in results_dict:\n",
        "            print(f\"\\nüéØ Model Performance:\")\n",
        "            print(f\"  Mean Absolute Error: {results_dict[best_model_name]['mae']:.3f}\")\n",
        "            print(f\"  Root Mean Squared Error: {results_dict[best_model_name]['rmse']:.3f}\")\n",
        "            print(f\"  R¬≤ Score: {results_dict[best_model_name]['r2']:.3f}\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è Model performance metrics not available (no labeled data or model not trained).\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No processed audio files or data available for reporting.\")\n",
        "    print(\"Please ensure you have uploaded your audio files to '/content/audio_data' \")\n",
        "    print(\"and re-run all cells from the 'Environment Setup & Data Exploration' section.\")\n",
        "\n",
        "print(f\"\\nüíæ Output Files Generated:\")\n",
        "print(\"  ‚úÖ /kaggle/working/submission.csv\")\n",
        "print(\"  ‚úÖ /kaggle/working/detailed_results.csv\")\n",
        "print(\"  ‚úÖ /kaggle/working/processed_transcripts.csv\")\n",
        "print(\"  ‚úÖ /kaggle/working/full_dataset.csv\")\n",
        "print(\"  ‚úÖ /kaggle/working/*.png (visualizations)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ GRAMMAR SCORING ENGINE COMPLETE!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zysv_tAYOif7",
        "outputId": "81c3a4c0-3d62-461e-f29b-96f1260f48c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìã GRAMMAR SCORING ENGINE - FINAL REPORT\n",
            "============================================================\n",
            "\n",
            "‚ö†Ô∏è No processed audio files or data available for reporting.\n",
            "Please ensure you have uploaded your audio files to '/content/audio_data' \n",
            "and re-run all cells from the 'Environment Setup & Data Exploration' section.\n",
            "\n",
            "üíæ Output Files Generated:\n",
            "  ‚úÖ /kaggle/working/submission.csv\n",
            "  ‚úÖ /kaggle/working/detailed_results.csv\n",
            "  ‚úÖ /kaggle/working/processed_transcripts.csv\n",
            "  ‚úÖ /kaggle/working/full_dataset.csv\n",
            "  ‚úÖ /kaggle/working/*.png (visualizations)\n",
            "\n",
            "============================================================\n",
            "üéâ GRAMMAR SCORING ENGINE COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}